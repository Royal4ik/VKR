{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('data/cleaned-data.csv', index_col=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#для сопоставления словам их tfIdf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn_deltatfidf import DeltaTfidfVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-граммная схема, к примеру (1, 3) значит - униграммы + биграммы + триграммы\n",
    "ngram_scheme = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для сопоставления словам их количества в твите\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#для сопоставления словам их tfIdf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn_deltatfidf import DeltaTfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20001    1\n",
       "20002    1\n",
       "20003    1\n",
       "20004    1\n",
       "20005    1\n",
       "20006    1\n",
       "20007    1\n",
       "20008    1\n",
       "20009    1\n",
       "20010    1\n",
       "20011    1\n",
       "20012    1\n",
       "20013    1\n",
       "20014    1\n",
       "20015    1\n",
       "20016    1\n",
       "20017    1\n",
       "20018    1\n",
       "20019    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][20001:20020]\n",
    "dataset['label'][20001:20020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram Scheme: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print('N-gram Scheme:', ngram_scheme)\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer = \"word\", ngram_range=ngram_scheme) \n",
    "#delta_vectorizer = DeltaTfidfVectorizer(analyzer='word', ngram_range=ngram_scheme)\n",
    "tf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=ngram_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000    сегодня был день супер море эмоций вечер конеч...\n",
       "20000    очень обидно когда подруга начинает репостить ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = tf_vectorizer\n",
    "#vectorizer = delta_vectorizer\n",
    "y = dataset['label']\n",
    "X = vectorizer.fit_transform(dataset['text'])\n",
    "dataset['text'][20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем классификатор\n",
    "X_train, X_test, y_train, y_test =\\\n",
    " train_test_split(X, dataset['label'], test_size=0.3)\n",
    "\n",
    "#cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "start_time = time.time()\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = linear_model.SGDClassifier(alpha=1e-05, loss='hinge', penalty='l2')\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.71      0.74     33347\n",
      "           1       0.74      0.81      0.77     34669\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     68016\n",
      "   macro avg       0.76      0.76      0.76     68016\n",
      "weighted avg       0.76      0.76      0.76     68016\n",
      "\n",
      "0.758277464126088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.71      0.74     33347\n",
      "           1       0.74      0.81      0.77     34669\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     68016\n",
      "   macro avg       0.76      0.76      0.76     68016\n",
      "weighted avg       0.76      0.76      0.76     68016\n",
      "\n",
      "0.758277464126088\n",
      "('dd', 6.759496681076041)\n",
      "('ddd', 5.674772256172816)\n",
      "('ахахах', 4.226849764665232)\n",
      "('ахах', 4.134681624695558)\n",
      "('ахаха', 3.9924989695506086)\n",
      "('не плохо', 3.888750232306505)\n",
      "('не зря', 3.8171341397915843)\n",
      "('приятно', 3.7900635317035722)\n",
      "('не за', 3.7262001964775697)\n",
      "('обожаю', 3.617948494001131)\n",
      "('oo', -8.174419850948516)\n",
      "('оо', -7.906529396405518)\n",
      "('обидно', -6.295175222295762)\n",
      "('жаль', -6.174112890901927)\n",
      "('не', -5.797605413147704)\n",
      "('скучаю', -5.757180384806332)\n",
      "('жалко', -5.708223914999972)\n",
      "('печально', -5.686035680108254)\n",
      "('блин', -5.378566805218958)\n",
      "('грустно', -5.2565396855765885)\n",
      "[ 1  1 -1]\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = linear_model.SGDClassifier(alpha=1e-05, loss='hinge', penalty='l2')\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))\n",
    "print (clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "import pickle as cPickle\n",
    "\n",
    "with open('my_classifier.pkl', 'wb') as fid:\n",
    "    cPickle.dump(clf, fid)    \n",
    "with open('my_vectorizer.pkl', 'wb') as vect:\n",
    "    cPickle.dump(vectorizer, vect)  \n",
    "\n",
    "# load it again\n",
    "with open('my_classifier.pkl', 'rb') as fid:\n",
    "    clf_loaded = cPickle.load(fid)\n",
    "\n",
    "pred1 = clf_loaded.predict(X_test)\n",
    "print(classification_report(y_test, pred1))\n",
    "print (clf_loaded.score(X_test, y_test))\n",
    "\n",
    "\n",
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        vectorizer.get_feature_names(), clf.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "#     ('excellent', 0.9288812418118644)\n",
    "#     ('perfect', 0.7934641227980576)\n",
    "#     ('great', 0.675040909917553)\n",
    "#     ('amazing', 0.6160398142631545)\n",
    "#     ('superb', 0.6063967799425831)\n",
    "    \n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)\n",
    "\n",
    "texts = [u'у меня всё хорошо',\n",
    "         u'что делаешь сейчас',\n",
    "         u'как же всё плохо ахаха']\n",
    "p = vectorizer.transform(texts)\n",
    "pred2 = clf.predict(p)\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1].toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-bf0a99ce1741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_to_coef = {\n\u001b[0;32m      2\u001b[0m     word: coef for word, coef in zip(\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     )\n\u001b[0;32m      5\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8730246707522155\n"
     ]
    }
   ],
   "source": [
    "print (clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      " f1: 0.73 (+/- 0.00) [MultinomialNB]\n",
      " recall: 0.71 (+/- 0.00) [MultinomialNB]\n",
      " precision: 0.75 (+/- 0.00) [MultinomialNB]\n",
      " Accuracy [0.7274409929371912]\n",
      "---Classifier MultinomialNB use 13.369346857070923 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#наивный байес\n",
    "clf = MultinomialNB()\n",
    "print('10-fold cross validation:\\n')\n",
    "start_time = time.time()\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=cv.split(X), scoring ='f1')\n",
    "print(\" f1: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), 'MultinomialNB'))\n",
    "\n",
    "recall_score = cross_val_score(clf, X,y, cv=cv.split(X), scoring ='recall')\n",
    "print(\" recall: %0.2f (+/- %0.2f) [%s]\" % (recall_score.mean(), recall_score.std(), 'MultinomialNB'))\n",
    "\n",
    "precision_score = cross_val_score(clf, X,y, cv=cv.split(X), scoring='precision')\n",
    "print(\" precision: %0.2f (+/- %0.2f) [%s]\" % (precision_score.mean(), precision_score.std(), 'MultinomialNB'))\n",
    "\n",
    "NB_res = cross_val_score(clf, X, y, cv=10)\n",
    "print(\" Accuracy [%s]\" %(NB_res.mean()))\n",
    "print(\"---Classifier %s use %s seconds ---\" %('MultinomialNB', (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
